import os
import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

# ãƒ­ãƒ¼ã‚«ãƒ«ç”¨ï¼š.env ã‚’èª­ã¿è¾¼ã‚€ï¼ˆCloudã§ã¯ .env ã¯ç„¡ã„ãŒå®³ã¯ãªã„ï¼‰
load_dotenv()


def get_api_key() -> str:
    """ãƒ­ãƒ¼ã‚«ãƒ«(.env) â†’ Cloud(Secrets) ã®é †ã«APIã‚­ãƒ¼ã‚’å–å¾—"""
    key = os.getenv("OPENAI_API_KEY")

    if not key:
        try:
            key = st.secrets["OPENAI_API_KEY"]
        except Exception:
            key = None

    return key


OPENAI_API_KEY = get_api_key()

st.set_page_config(page_title="Streamlit LLM App", page_icon="ğŸ¤–")

st.title("ğŸ¤– Streamlit Ã— LangChain LLMã‚¢ãƒ—ãƒª")
st.write(
    """
### ã“ã®ã‚¢ãƒ—ãƒªã§ã§ãã‚‹ã“ã¨
- å…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’LLMã«æ¸¡ã—ã¦å›ç­”ã‚’è¡¨ç¤ºã—ã¾ã™
- ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ã€Œå°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã€ã‚’é¸ã¶ã¨ã€LLMã®å½¹å‰²ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰ãŒåˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™

### ä½¿ã„æ–¹
1. å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸ã¶
2. è³ªå•ã‚’å…¥åŠ›ã™ã‚‹
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™
"""
)

if not OPENAI_API_KEY:
    st.error("OPENAI_API_KEY ãŒæœªè¨­å®šã§ã™ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã¯ .envã€Cloudã¯ Secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ï¼ˆA/Bï¼‰
expert_type = st.radio(
    "å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
    options=["A: ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒ", "B: æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼"],
    horizontal=True,
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆ1ã¤ï¼‰
user_text = st.text_input(
    "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ",
    placeholder="ä¾‹ï¼šè»¢è·ã®è‡ªå·±PRã‚’æ·»å‰Šã—ã¦ / 2æ³Š3æ—¥ã®æ—…è¡Œãƒ—ãƒ©ãƒ³ä½œã£ã¦",
)


# å¿…é ˆï¼šé–¢æ•°ï¼ˆå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼‹é¸æŠå€¤ â†’ LLMå›ç­”ï¼‰
def get_llm_answer(input_text: str, selected_expert: str) -> str:
    if selected_expert.startswith("A"):
        system_message = (
            "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒã§ã™ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çŠ¶æ³ã‚’æ•´ç†ã—ã€ç¾å®Ÿçš„ã§å®Ÿè¡Œå¯èƒ½ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚"
            "ç®‡æ¡æ›¸ãã‚’å¤šã‚ã«ã€å¿…è¦ãªã‚‰è¿½åŠ è³ªå•ã‚’1ã¤ã ã‘æ·»ãˆã¦ãã ã•ã„ã€‚"
        )
    else:
        system_message = (
            "ã‚ãªãŸã¯ãƒ—ãƒ­ã®æ—…è¡Œãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã§ã™ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›ã«æ²¿ã£ãŸæ—…è¡Œãƒ—ãƒ©ãƒ³ï¼ˆè¡Œç¨‹ãƒ»ç§»å‹•ãƒ»äºˆç®—æ„Ÿãƒ»æ³¨æ„ç‚¹ï¼‰ã‚’æ—¥æœ¬èªã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚"
            "è¦‹å‡ºã—ï¼‹ç®‡æ¡æ›¸ãä¸­å¿ƒã§ã€å¿…è¦ãªã‚‰è¿½åŠ è³ªå•ã‚’1ã¤ã ã‘æ·»ãˆã¦ãã ã•ã„ã€‚"
        )

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_message),
            ("user", "{question}"),
        ]
    )

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.7,
        api_key=OPENAI_API_KEY,
    )

    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run(question=input_text)


# ãƒœã‚¿ãƒ³ã§å®Ÿè¡Œ
if st.button("é€ä¿¡", type="primary"):
    if not user_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("å›ç­”ç”Ÿæˆä¸­..."):
            answer = get_llm_answer(user_text, expert_type)
        st.subheader("å›ç­”")
        st.write(answer)

st.caption("â€»æ³¨æ„ï¼š.envï¼ˆAPIã‚­ãƒ¼ï¼‰ã¯GitHubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãªã„ã§ãã ã•ã„ã€‚")
